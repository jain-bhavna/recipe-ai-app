{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Food-101 EfficientNet Training\n",
    "\n",
    "This notebook trains a food dish classifier using EfficientNet-B0 fine-tuned on the Food-101 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, datasets\n",
    "import timm\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from google.colab import files\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Dataset\n",
    "if not os.path.exists('food-101.tar.gz'):\n",
    "    !wget http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz\n",
    "    print(\"Downloaded food-101.tar.gz\")\n",
    "\n",
    "if not os.path.exists('food-101'):\n",
    "    !tar xzf food-101.tar.gz\n",
    "    print(\"Extracted food-101.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebuild Dataset Structure\n",
    "original_data_dir = Path('food-101')\n",
    "images_dir = original_data_dir / 'images'\n",
    "meta_dir = original_data_dir / 'meta'\n",
    "\n",
    "train_meta_file = meta_dir / 'train.txt'\n",
    "test_meta_file = meta_dir / 'test.txt'\n",
    "\n",
    "rebuilt_dir = Path('food101_rebuilt')\n",
    "train_dir = rebuilt_dir / 'train'\n",
    "val_dir = rebuilt_dir / 'val'\n",
    "\n",
    "if not rebuilt_dir.exists():\n",
    "    print(\"Rebuilding dataset structure...\")\n",
    "    \n",
    "    # Create directories\n",
    "    for split_dir in [train_dir, val_dir]:\n",
    "        split_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "    # Helper to process files\n",
    "    def process_split(meta_file, destination):\n",
    "        with open(meta_file, 'r') as f:\n",
    "            image_paths = [line.strip() for line in f.readlines()]\n",
    "            \n",
    "        for img_path_str in tqdm(image_paths, desc=f\"Processing {destination.name}\"):\n",
    "            class_name = img_path_str.split('/')[0]\n",
    "            \n",
    "            # Source file\n",
    "            src_file = images_dir / f\"{img_path_str}.jpg\"\n",
    "            \n",
    "            # Dest directory\n",
    "            dest_class_dir = destination / class_name\n",
    "            dest_class_dir.mkdir(exist_ok=True)\n",
    "            \n",
    "            # Copy\n",
    "            shutil.copy(src_file, dest_class_dir / f\"{src_file.name}\")\n",
    "\n",
    "    process_split(train_meta_file, train_dir)\n",
    "    process_split(test_meta_file, val_dir)\n",
    "    \n",
    "    print(\"Dataset rebuild complete.\")\n",
    "else:\n",
    "    print(\"Dataset already rebuilt.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloaders\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=train_transform)\n",
    "val_dataset = datasets.ImageFolder(root=val_dir, transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "class_names = train_dataset.classes\n",
    "print(f\"Number of classes: {len(class_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Setup\n",
    "model = timm.create_model('efficientnet_b0', pretrained=True)\n",
    "\n",
    "# Freeze backbone\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace classifier head\n",
    "num_features = model.classifier.in_features\n",
    "model.classifier = nn.Linear(num_features, len(class_names))\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Setup\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "num_epochs = 6\n",
    "best_acc = 0.0\n",
    "save_path = \"food101_efficientnet.pt\"\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(\"-\" * 10)\n",
    "\n",
    "    # Training Phase\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for inputs, labels in tqdm(train_loader, desc=\"Training\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct_train += torch.sum(preds == labels.data)\n",
    "        total_train += labels.size(0)\n",
    "\n",
    "    scheduler.step()\n",
    "    \n",
    "    epoch_loss = running_loss / total_train\n",
    "    epoch_acc = correct_train.double() / total_train\n",
    "    print(f\"Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "    # Validation Phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(val_loader, desc=\"Validation\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct_val += torch.sum(preds == labels.data)\n",
    "            total_val += labels.size(0)\n",
    "\n",
    "    val_epoch_loss = val_loss / total_val\n",
    "    val_epoch_acc = correct_val.double() / total_val\n",
    "    print(f\"Val Loss: {val_epoch_loss:.4f} Acc: {val_epoch_acc:.4f}\")\n",
    "\n",
    "    # Save best model\n",
    "    if val_epoch_acc > best_acc:\n",
    "        best_acc = val_epoch_acc\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(f\"Saved best model weights to {save_path}\")\n",
    "\n",
    "print(f\"Best Validation Accuracy: {best_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference Test\n",
    "def predict_image(image_path, model, transform, class_names):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    data = transform(image).unsqueeze(0).to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(data)\n",
    "        _, pred = torch.max(output, 1)\n",
    "        prob = torch.nn.functional.softmax(output, dim=1)[0] * 100\n",
    "    \n",
    "    print(f\"Predicted: {class_names[pred.item()]} ({prob[pred.item()]:.2f}%)\")\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Test on a random validation image\n",
    "random_class = random.choice(class_names)\n",
    "random_img_name = random.choice(os.listdir(val_dir / random_class))\n",
    "test_image_path = val_dir / random_class / random_img_name\n",
    "\n",
    "print(f\"Testing on image: {test_image_path}\")\n",
    "print(f\"True Label: {random_class}\")\n",
    "predict_image(test_image_path, model, val_transform, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Model\n",
    "if os.path.exists(\"food101_efficientnet.pt\"):\n",
    "    files.download(\"food101_efficientnet.pt\")\n",
    "    print(\"Downloading model file...\")\n",
    "else:\n",
    "    print(\"Model file not found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
